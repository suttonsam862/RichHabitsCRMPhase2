title: Zero‑DB‑Error Enforcement Framework (Schema‑First + Supabase Sync + RLS‑Safe Writes)
id: 2025-08-24-zero-db-error-framework
owner: platform
status: proposed
applies_to: repo
summary: |
  Install an enforced, automated guardrail system that prevents all database schema drift,
  stale PostgREST cache errors, RLS permission surprises, and "column not found" bugs before they
  can reach runtime. The framework adds schema introspection, schema checks, a self-test that
  proves writes are safe, and a PostgREST schema reload tool. It also wires server-side writes to
  the Supabase service role (bypassing RLS by design on the server), and adds an agent operating
  manual + CR template that forces DB validation before a PR/task can claim success.

acceptance_criteria:
  - docs/schema/snapshot.json is generated by `npm run db:schema:dump` and includes public+auth tables.
  - `npm run db:schema:check` passes; fails fast if any required columns/tables are missing (e.g., org_sports.contact_user_id).
  - `npm run db:selftest` passes; proves we can insert/delete a test org + org_sports row without RLS or constraint errors.
  - A migration exists to add org_sports.contact_user_id (idempotent) and notifies PostgREST to reload schema.
  - Server uses service-role Supabase client for writes (no client-side exposure). RLS bypassed only on server.
  - `npm run verify` (dump + check + selftest) runs clean locally.
  - Preflight runs schema dump & check so tasks can’t “pass” with DB drift.
  - “Agent Operating Manual” and “CR Template” are added and referenced by future CRs.
  - Express trust proxy is set to eliminate rate-limit header validation errors in Replit/Proxy environments.

edits:
  - action: ensure_packages
    dev: [ "tsx", "zod" ]
    prod: [ "@supabase/supabase-js", "pg" ]

  - action: patch_json
    file: package.json
    merge:
      scripts:
        db:schema:dump: "tsx scripts/db/schema-dump.ts"
        db:schema:check: "tsx scripts/db/schema-check.ts"
        db:selftest: "tsx scripts/db/selftest.ts"
        db:reload-postgrest: "tsx scripts/db/reload-postgrest.ts"
        verify: "npm run db:schema:dump && npm run db:schema:check && npm run db:selftest"

  - action: write_file
    path: server/lib/supabaseAdmin.ts
    contents: |
      import { createClient } from '@supabase/supabase-js';

      const url = process.env.SUPABASE_URL || process.env.VITE_SUPABASE_URL!;
      const key = process.env.SUPABASE_SERVICE_ROLE_KEY!; // server-only key, bypasses RLS

      export const supabaseAdmin = createClient(url, key, {
        auth: { autoRefreshToken: false, persistSession: false, detectSessionInUrl: false },
      });

  - action: write_file
    path: scripts/db/schema-dump.ts
    contents: |
      import 'dotenv/config';
      import pg from 'pg';
      import { writeFileSync, mkdirSync } from 'fs';
      import { join } from 'path';

      const OUT = join(process.cwd(), 'docs/schema/snapshot.json');

      async function main() {
        const pool = new pg.Pool({ connectionString: process.env.DATABASE_URL });
        const columns = await pool.query(`
          select c.table_schema, c.table_name, c.column_name, c.data_type, c.is_nullable, c.character_maximum_length
          from information_schema.columns c
          where c.table_schema in ('public','auth')
          order by c.table_schema, c.table_name, c.ordinal_position
        `);
        const constraints = await pool.query(`
          select tc.table_schema, tc.table_name, tc.constraint_name, tc.constraint_type
          from information_schema.table_constraints tc
          where tc.table_schema in ('public','auth')
          order by tc.table_schema, tc.table_name, tc.constraint_name
        `);
        const rls = await pool.query(`
          select schemaname as table_schema, tablename as table_name, rowsecurity as rls_enabled
          from pg_tables
          where schemaname in ('public','auth')
        `);
        mkdirSync(join(process.cwd(), 'docs/schema'), { recursive: true });
        writeFileSync(OUT, JSON.stringify({
          generatedAt: new Date().toISOString(),
          columns: columns.rows,
          constraints: constraints.rows,
          rls: rls.rows
        }, null, 2));
        await pool.end();
        console.log('Schema snapshot written:', OUT);
      }
      main().catch((e)=>{ console.error(e); process.exit(1); });

  - action: write_file
    path: scripts/db/schema-check.ts
    contents: |
      import { readFileSync } from 'fs';
      import { join } from 'path';

      type Col = { table_schema:string; table_name:string; column_name:string; data_type:string };

      // Extend this list as code relies on more columns.
      const REQUIRED: Array<{schema:string; table:string; col:string; type?:string}> = [
        { schema:'public', table:'organizations', col:'brand_primary' },
        { schema:'public', table:'organizations', col:'brand_secondary' },
        { schema:'public', table:'org_sports',   col:'contact_user_id', type:'uuid' },
      ];

      function main() {
        const snapPath = join(process.cwd(), 'docs/schema/snapshot.json');
        const snap = JSON.parse(readFileSync(snapPath, 'utf8'));
        const cols: Col[] = snap.columns;
        const missing: string[] = [];
        const typeMismatches: string[] = [];

        for (const req of REQUIRED) {
          const found = cols.find(c =>
            c.table_schema === req.schema &&
            c.table_name   === req.table &&
            c.column_name  === req.col
          );
          if (!found) {
            missing.push(`${req.schema}.${req.table}.${req.col}`);
          } else if (req.type && found.data_type !== req.type) {
            typeMismatches.push(`${req.schema}.${req.table}.${req.col} expected ${req.type} got ${found.data_type}`);
          }
        }

        if (missing.length || typeMismatches.length) {
          console.error('❌ Schema check failed.');
          if (missing.length) console.error('Missing:', missing.join(', '));
          if (typeMismatches.length) console.error('Type mismatches:', typeMismatches.join(', '));
          process.exit(1);
        }
        console.log('✅ Schema check OK.');
      }
      main();

  - action: write_file
    path: scripts/db/selftest.ts
    contents: |
      import 'dotenv/config';
      import { createClient } from '@supabase/supabase-js';

      async function main() {
        const url = process.env.SUPABASE_URL || process.env.VITE_SUPABASE_URL!;
        const key = process.env.SUPABASE_SERVICE_ROLE_KEY!;
        const sb = createClient(url, key);

        // Probe schema cache quickly
        const probe = await sb.from('org_sports').select('contact_user_id').limit(1);
        if (probe.error && probe.error.message.includes('schema cache')) {
          throw new Error(`PostgREST cache stale: ${probe.error.message}`);
        }

        // Insert an organization
        const name = `__selftest_org_${Date.now()}`;
        const orgIns = await sb.from('organizations').insert({
          name, brand_primary:'#222222', brand_secondary:'#444444', status:'active'
        }).select('id').single();
        if (orgIns.error) throw new Error(`Insert organizations failed: ${orgIns.error.message}`);

        // Insert org_sports row
        const sportIns = await sb.from('org_sports').insert({
          org_id: orgIns.data!.id, sport: 'wrestling', contact_user_id: null
        });
        if (sportIns.error) throw new Error(`Insert org_sports failed: ${sportIns.error.message}`);

        // Cleanup (best effort)
        await sb.from('org_sports').delete().eq('org_id', orgIns.data!.id);
        await sb.from('organizations').delete().eq('id', orgIns.data!.id);

        console.log('✅ DB selftest passed (writes via service role, no RLS/constraint errors).');
      }

      main().catch((e)=>{ console.error('❌ DB selftest failed:', e.message); process.exit(1); });

  - action: write_file
    path: scripts/db/reload-postgrest.ts
    contents: |
      import 'dotenv/config';
      import pg from 'pg';

      async function main() {
        const pool = new pg.Pool({ connectionString: process.env.DATABASE_URL });
        await pool.query(`SELECT pg_notify('pgrst','reload schema')`);
        await pool.end();
        console.log('PostgREST schema cache reloaded.');
      }
      main().catch((e)=>{ console.error(e); process.exit(1); });

  - action: write_file
    path: server/migrations/2025_08_24_orgsports_contact_user_id.sql
    contents: |
      -- Idempotent migration: ensure column present
      ALTER TABLE public.org_sports
        ADD COLUMN IF NOT EXISTS contact_user_id uuid;

      DO $$
      BEGIN
        IF NOT EXISTS (
          SELECT 1 FROM pg_constraint WHERE conname = 'org_sports_contact_user_fk'
        ) THEN
          ALTER TABLE public.org_sports
            ADD CONSTRAINT org_sports_contact_user_fk
            FOREIGN KEY (contact_user_id) REFERENCES auth.users(id)
            ON DELETE SET NULL;
        END IF;
      END $$;

      -- Force PostgREST schema cache reload immediately
      SELECT pg_notify('pgrst', 'reload schema');

  - action: patch_in_file
    file: scripts/preflight.cjs
    after: "// === END: preflight env checks ==="
    insert: |
      const { execSync } = require('child_process');
      try {
        execSync('npm run db:schema:dump', { stdio:'inherit' });
        execSync('npm run db:schema:check', { stdio:'inherit' });
      } catch (e) {
        console.error('Preflight DB checks failed. Fix schema drift before continuing.');
        process.exit(1);
      }

  - action: patch_in_file
    file: server/index.ts
    find: "const app = express();"
    replace_with: |
      const app = express();
      // Replit/Proxy environments set X-Forwarded-For; trust proxy for rate-limit keying
      app.set('trust proxy', 1);

  - action: modify_server_writes_to_service_role
    note: |
      Find the POST create handler for /api/v1/organizations and ensure all writes use `supabaseAdmin`.
      If no dedicated create file exists, create one and mount it.
    create_if_missing:
      path: server/routes/organizations/create.ts
      contents: |
        import { Router } from 'express';
        import { z } from 'zod';
        import { supabaseAdmin } from '../../lib/supabaseAdmin.js';

        const router = Router();

        const OrgSchema = z.object({
          name: z.string().min(2),
          brand_primary: z.string().regex(/^#/),
          brand_secondary: z.string().regex(/^#/),
          is_business: z.boolean().optional(),
          sports: z.array(z.object({
            sport: z.string(),
            contact_user_id: z.string().uuid().nullable().optional()
          })).optional()
        });

        router.post('/', async (req, res) => {
          const parsed = OrgSchema.safeParse(req.body);
          if (!parsed.success) return res.status(400).json({ error: parsed.error.flatten() });
          const payload = parsed.data;

          const orgRes = await supabaseAdmin
            .from('organizations')
            .insert({
              name: payload.name,
              brand_primary: payload.brand_primary,
              brand_secondary: payload.brand_secondary,
              is_business: payload.is_business ?? false,
              status: 'active'
            })
            .select('id')
            .single();

          if (orgRes.error) return res.status(400).json({ error: orgRes.error });

          if (payload.sports?.length) {
            const rows = payload.sports.map(s => ({
              org_id: orgRes.data!.id,
              sport: s.sport,
              contact_user_id: s.contact_user_id ?? null
            }));
            const sportRes = await supabaseAdmin.from('org_sports').insert(rows);
            if (sportRes.error) return res.status(400).json({ error: sportRes.error });
          }

          return res.json({ success: true, data: { id: orgRes.data!.id } });
        });

        export default router;

  - action: mount_router_if_needed
    file: server/routes/organizations/index.ts
    hint: |
      Ensure the create router above is mounted. If index.ts exists, add:
      import createRouter from './create.js';
      router.use('/', createRouter);

  - action: write_file
    path: docs/agent/operating-manual.md
    contents: |
      # Agent Operating Manual – ZERO-DB-ERROR POLICY

      You must operate schema-first. Before any change:
      1) Run: `npm run db:schema:dump`
      2) Read: `docs/schema/snapshot.json`
      3) Only reference tables/columns that exist in the snapshot unless you also supply an idempotent SQL migration that creates them AND includes: `SELECT pg_notify('pgrst','reload schema');`
      4) All server-side writes must use `server/lib/supabaseAdmin.ts`. Do not expose service role key to client.
      5) After changes, I will run: `npm run verify`. Your work is not done until it passes locally.

      Deliverables in every task:
      - Code changes
      - **Database Changes & Verification** with: tables touched, existence checks, migrations, RLS impact, constraints, and performance notes
      - Rollback plan

  - action: write_file
    path: architecture/agent/CR_TEMPLATE.md
    contents: |
      # Change Request – ZERO-DB-ERROR PLEDGE

      ## Task
      - One atomic change; no mixed concerns.

      ## DB Schema Snapshot to honor
      - File: docs/schema/snapshot.json

      ## Required Outcomes
      - No DB runtime errors (missing table/column, RLS, constraint, type, timeout).
      - If new schema is required: include idempotent SQL migration with `SELECT pg_notify('pgrst','reload schema');`
      - Server writes use `supabaseAdmin`.
      - Provide proof via self-test or tests.

      ## Deliverables
      1. Code changes.
      2. Database Changes & Verification:
         - Tables/Columns touched:
         - Existence confirmed in snapshot:
         - New migrations included:
         - RLS impact (reads anon; writes service role):
         - Constraints (unique/FK/not null):
         - Performance (indexes if needed):
      3. How to run:
         ```
         npm run db:schema:dump && npm run db:schema:check && npm run db:selftest
         npm run dev
         ```
      4. Rollback plan.

post_steps:
  - "Apply migration file server/migrations/2025_08_24_orgsports_contact_user_id.sql (via your migration runner or Supabase SQL editor)."
  - "Run: npm run db:reload-postgrest"
  - "Run: npm run verify"
  - "Run app: npm run dev"
  - "Try creating an organization from the UI; it should succeed with 200 and be visible in list."
rollback_plan: |
  - Remove any files added by this CR.
  - Revert package.json changes to remove db:* and verify scripts.
  - If the org_sports FK or column must be removed:
    ALTER TABLE public.org_sports DROP CONSTRAINT IF EXISTS org_sports_contact_user_fk;
    ALTER TABLE public.org_sports DROP COLUMN IF EXISTS contact_user_id;
  - Run: SELECT pg_notify('pgrst','reload schema');
notes:
  - Ensure env vars are set: SUPABASE_URL, VITE_SUPABASE_URL, VITE_SUPABASE_ANON_KEY, SUPABASE_SERVICE_ROLE_KEY, DATABASE_URL.
  - The service role key is server-only; never expose to client bundles.
  - The `app.set('trust proxy', 1)` line resolves express-rate-limit validation in proxied dev environments (Replit).
